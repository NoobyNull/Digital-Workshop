"""
Theme Cache Module

This module provides memory-efficient theme caching for the unified theme system.
It manages theme data caching with intelligent memory management and performance optimization.

Key Features:
- Memory-efficient LRU caching for theme data
- Intelligent cache size management based on available RAM
- Thread-safe cache operations with proper locking
- Cache performance monitoring and statistics
- Automatic cache cleanup and memory pressure handling
- Compressed theme data storage for memory efficiency

Cache Strategy:
- LRU (Least Recently Used) eviction policy
- Adaptive cache sizing based on system memory
- Compressed storage for large theme configurations
- Background cleanup to prevent memory fragmentation
- Performance monitoring for cache hit/miss ratios
"""

import time
from typing import Dict, Any, Optional
from collections import OrderedDict
from PySide6.QtCore import QMutex, QMutexLocker, QTimer
from src.core.logging_config import get_logger

logger = get_logger(__name__)


class CacheEntry:
    """
    Individual cache entry with metadata.

    Tracks access patterns, memory usage, and compression status
    for intelligent cache management decisions.
    """

    def __init__(self, key: str, data: Dict[str, Any], compressed: bool = False):
        """
        Initialize cache entry.

        Args:
            key: Cache key
            data: Theme data to cache
            compressed: Whether data is compressed
        """
        self.key = key
        self.data = data
        self.compressed = compressed
        self.created_time = time.time()
        self.last_access_time = time.time()
        self.access_count = 0
        self.memory_size = self._calculate_memory_size()

    def _calculate_memory_size(self) -> int:
        """Calculate approximate memory size of cached data."""
        try:
            import sys
            return sys.getsizeof(str(self.data))
        except Exception:
            return 1024  # Default estimate

    def access(self) -> None:
        """Mark entry as accessed."""
        self.last_access_time = time.time()
        self.access_count += 1

    def age(self) -> float:
        """Get age of entry in seconds."""
        return time.time() - self.created_time

    def time_since_access(self) -> float:
        """Get time since last access in seconds."""
        return time.time() - self.last_access_time


class ThemeCache:
    """
    Memory-efficient theme caching system with intelligent management.

    Provides high-performance caching for theme data with:
    - LRU eviction for optimal memory usage
    - Adaptive sizing based on system resources
    - Thread-safe operations
    - Memory pressure detection and response
    - Performance monitoring and statistics

    Memory Management:
    - Automatic cache size adjustment based on available RAM
    - Memory pressure detection and cleanup
    - Compressed storage for large theme configurations
    - Background cleanup to prevent fragmentation
    """

    def __init__(self, max_size: int = None):
        """
        Initialize theme cache.

        Args:
            max_size: Maximum cache size in entries (None for adaptive)
        """
        # Core cache storage (LRU ordered)
        self._cache: OrderedDict[str, CacheEntry] = OrderedDict()
        self._cache_mutex = QMutex()

        # Size management
        self._max_size = max_size or self._calculate_optimal_size()
        self._current_size = 0

        # Memory management
        self._memory_limit = self._calculate_memory_limit()
        self._current_memory = 0
        self._memory_pressure_threshold = 0.8  # 80% of limit

        # Performance tracking
        self._hits = 0
        self._misses = 0
        self._evictions = 0
        self._cleanup_count = 0

        # Background cleanup
        self._cleanup_timer = QTimer()
        self._cleanup_timer.timeout.connect(self._background_cleanup)
        self._cleanup_timer.start(30000)  # Cleanup every 30 seconds

        # Compression support
        self._compression_enabled = True

        logger.info(f"ThemeCache initialized: max_size={self._max_size}, memory_limit={self._memory_limit} bytes")

    def get(self, key: str) -> Optional[Dict[str, Any]]:
        """
        Get theme data from cache.

        Args:
            key: Cache key

        Returns:
            Theme data if found, None otherwise
        """
        with QMutexLocker(self._cache_mutex):
            if key in self._cache:
                entry = self._cache[key]
                entry.access()

                # Move to end (most recently used)
                self._cache.move_to_end(key)

                self._hits += 1
                logger.debug(f"Cache hit for key: {key}")
                return entry.data.copy()

            self._misses += 1
            logger.debug(f"Cache miss for key: {key}")
            return None

    def put(self, key: str, data: Dict[str, Any], compress: bool = None) -> bool:
        """
        Put theme data in cache.

        Args:
            key: Cache key
            data: Theme data to cache
            compress: Whether to compress data (None for auto)

        Returns:
            True if data was cached, False if rejected
        """
        with QMutexLocker(self._cache_mutex):
            # Check if we need to evict entries
            if not self._can_accommodate(data):
                if not self._evict_entries():
                    logger.warning(f"Cannot accommodate new cache entry: {key}")
                    return False

            # Determine compression
            if compress is None:
                compress = self._should_compress(data)

            # Create cache entry
            entry = CacheEntry(key, data, compress)

            # Add to cache
            self._cache[key] = entry
            self._current_size += 1
            self._current_memory += entry.memory_size

            # Move to end (most recently used)
            self._cache.move_to_end(key)

            logger.debug(f"Cached theme data: {key} (compressed={compress})")
            return True

    def remove(self, key: str) -> bool:
        """
        Remove entry from cache.

        Args:
            key: Cache key to remove

        Returns:
            True if entry was removed, False if not found
        """
        with QMutexLocker(self._cache_mutex):
            if key in self._cache:
                entry = self._cache.pop(key)
                self._current_size -= 1
                self._current_memory -= entry.memory_size

                logger.debug(f"Removed cache entry: {key}")
                return True

            return False

    def clear(self) -> None:
        """Clear all cache entries."""
        with QMutexLocker(self._cache_mutex):
            self._cache.clear()
            self._current_size = 0
            self._current_memory = 0

            logger.info("Cache cleared")

    def contains(self, key: str) -> bool:
        """
        Check if key exists in cache.

        Args:
            key: Cache key to check

        Returns:
            True if key exists in cache
        """
        with QMutexLocker(self._cache_mutex):
            return key in self._cache

    def size(self) -> int:
        """
        Get current cache size.

        Returns:
            Number of entries in cache
        """
        with QMutexLocker(self._cache_mutex):
            return self._current_size

    def memory_usage(self) -> int:
        """
        Get current memory usage in bytes.

        Returns:
            Memory usage in bytes
        """
        with QMutexLocker(self._cache_mutex):
            return self._current_memory

    def get_stats(self) -> Dict[str, Any]:
        """
        Get comprehensive cache statistics.

        Returns:
            Dictionary containing cache performance metrics
        """
        with QMutexLocker(self._cache_mutex):
            total_requests = self._hits + self._misses
            hit_ratio = self._hits / total_requests if total_requests > 0 else 0

            return {
                "size": self._current_size,
                "max_size": self._max_size,
                "memory_usage_bytes": self._current_memory,
                "memory_limit_bytes": self._memory_limit,
                "memory_usage_percent": (self._current_memory / self._memory_limit) if self._memory_limit > 0 else 0,
                "hits": self._hits,
                "misses": self._misses,
                "hit_ratio": hit_ratio,
                "evictions": self._evictions,
                "cleanup_count": self._cleanup_count,
                "compression_enabled": self._compression_enabled,
                "oldest_entry_age": self._get_oldest_entry_age(),
                "newest_entry_age": self._get_newest_entry_age()
            }

    def resize(self, new_max_size: int) -> None:
        """
        Resize cache to new maximum size.

        Args:
            new_max_size: New maximum cache size
        """
        with QMutexLocker(self._cache_mutex):
            self._max_size = new_max_size

            # Evict entries if we're over the new limit
            while self._current_size > self._max_size:
                self._evict_lru()

            logger.info(f"Cache resized to max_size={self._max_size}")

    def enable_compression(self) -> None:
        """Enable cache compression."""
        with QMutexLocker(self._cache_mutex):
            self._compression_enabled = True
            logger.debug("Cache compression enabled")

    def disable_compression(self) -> None:
        """Disable cache compression."""
        with QMutexLocker(self._cache_mutex):
            self._compression_enabled = False
            logger.debug("Cache compression disabled")

    def force_cleanup(self) -> None:
        """Force immediate cache cleanup."""
        self._background_cleanup()
        logger.debug("Forced cache cleanup completed")

    def _can_accommodate(self, data: Dict[str, Any]) -> bool:
        """
        Check if cache can accommodate new data.

        Args:
            data: Data to check

        Returns:
            True if data can be accommodated
        """
        # Check size limit
        if self._current_size >= self._max_size:
            return False

        # Check memory limit
        data_size = len(str(data))  # Approximate size
        if self._current_memory + data_size > self._memory_limit:
            return False

        return True

    def _evict_entries(self) -> bool:
        """
        Evict entries to make room for new data.

        Returns:
            True if space was freed, False if cache is full
        """
        # Try to evict based on LRU first
        if self._evict_lru():
            return True

        # If still no space, try to evict based on memory pressure
        if self._evict_under_pressure():
            return True

        return False

    def _evict_lru(self) -> bool:
        """
        Evict least recently used entry.

        Returns:
            True if entry was evicted, False if cache is empty
        """
        if not self._cache:
            return False

        # Get LRU entry (first in OrderedDict)
        key, entry = next(iter(self._cache.items()))

        # Remove entry
        del self._cache[key]
        self._current_size -= 1
        self._current_memory -= entry.memory_size
        self._evictions += 1

        logger.debug(f"Evicted LRU entry: {key}")
        return True

    def _evict_under_pressure(self) -> bool:
        """
        Evict entries under memory pressure.

        Returns:
            True if entries were evicted, False if no suitable entries
        """
        if not self._cache:
            return False

        # Find oldest entries to evict
        entries_to_evict = []
        for key, entry in self._cache.items():
            if entry.age() > 300:  # Older than 5 minutes
                entries_to_evict.append((key, entry))
                if len(entries_to_evict) >= 3:  # Evict up to 3 entries
                    break

        if not entries_to_evict:
            return False

        # Evict selected entries
        for key, entry in entries_to_evict:
            del self._cache[key]
            self._current_size -= 1
            self._current_memory -= entry.memory_size
            self._evictions += 1

        logger.debug(f"Evicted {len(entries_to_evict)} entries under memory pressure")
        return True

    def _should_compress(self, data: Dict[str, Any]) -> bool:
        """
        Determine if data should be compressed.

        Args:
            data: Data to check

        Returns:
            True if data should be compressed
        """
        if not self._compression_enabled:
            return False

        # Compress if data is large
        data_size = len(str(data))
        return data_size > 2048  # Compress if over 2KB

    def _calculate_optimal_size(self) -> int:
        """
        Calculate optimal cache size based on system resources.

        Returns:
            Optimal cache size in entries
        """
        try:
            import psutil
            memory_gb = psutil.virtual_memory().total / (1024**3)

            # Adaptive sizing based on available memory
            if memory_gb >= 8:
                return 100  # Large cache for systems with 8GB+
            elif memory_gb >= 4:
                return 50   # Medium cache for systems with 4GB+
            else:
                return 25   # Small cache for systems with <4GB

        except ImportError:
            # Fallback if psutil not available
            return 50

    def _calculate_memory_limit(self) -> int:
        """
        Calculate memory limit for cache.

        Returns:
            Memory limit in bytes
        """
        try:
            import psutil
            available_memory = psutil.virtual_memory().available

            # Use up to 1% of available memory for cache
            return int(available_memory * 0.01)

        except ImportError:
            # Fallback: 10MB limit
            return 10 * 1024 * 1024

    def _get_oldest_entry_age(self) -> float:
        """Get age of oldest cache entry."""
        if not self._cache:
            return 0.0

        oldest_entry = next(iter(self._cache.values()))
        return oldest_entry.age()

    def _get_newest_entry_age(self) -> float:
        """Get age of newest cache entry."""
        if not self._cache:
            return 0.0

        newest_entry = next(reversed(self._cache.values()))
        return newest_entry.age()

    def _background_cleanup(self) -> None:
        """Perform background cache cleanup."""
        with QMutexLocker(self._cache_mutex):
            # Remove entries older than 10 minutes
            current_time = time.time()
            keys_to_remove = []

            for key, entry in self._cache.items():
                if current_time - entry.created_time > 600:  # 10 minutes
                    keys_to_remove.append(key)

            # Remove old entries
            for key in keys_to_remove:
                if key in self._cache:
                    entry = self._cache.pop(key)
                    self._current_size -= 1
                    self._current_memory -= entry.memory_size

            if keys_to_remove:
                self._cleanup_count += 1
                logger.debug(f"Background cleanup removed {len(keys_to_remove)} old entries")

            # Check memory pressure and cleanup if needed
            memory_usage_ratio = self._current_memory / self._memory_limit if self._memory_limit > 0 else 0
            if memory_usage_ratio > self._memory_pressure_threshold:
                self._handle_memory_pressure()

    def _handle_memory_pressure(self) -> None:
        """Handle memory pressure by aggressive cleanup."""
        # Remove half of the entries under memory pressure
        entries_to_remove = len(self._cache) // 2
        if entries_to_remove == 0:
            return

        # Remove oldest entries first
        keys_to_remove = []
        for key in self._cache:
            keys_to_remove.append(key)
            if len(keys_to_remove) >= entries_to_remove:
                break

        for key in keys_to_remove:
            if key in self._cache:
                entry = self._cache.pop(key)
                self._current_size -= 1
                self._current_memory -= entry.memory_size

        logger.warning(f"Memory pressure cleanup removed {len(keys_to_remove)} entries")